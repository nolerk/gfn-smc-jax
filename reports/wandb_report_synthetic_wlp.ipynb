{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of runs in many_well-64d/pis: 5\n",
      "Number of runs in many_well-64d/dds: 5\n",
      "Number of runs in many_well-64d/lv: 5\n",
      "Number of runs in many_well-64d/tb: 5\n",
      "Number of runs in many_well-64d/gfnsmc: 5\n",
      "Number of runs in many_well-64d/gfnpiwbuf: 5\n",
      "Number of runs in many_well-64d/gfnsmcbuf: 5\n",
      "Number of runs in many_well-64d/gfnsmcpiwbuf: 5\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "api = wandb.Api()\n",
    "target_names = [\"many_well\"]  # many_well\n",
    "dims = [64]\n",
    "\n",
    "algorithm_names = [\n",
    "    \"pis\",\n",
    "    \"dds\",\n",
    "    \"lv\",\n",
    "    \"tb\",\n",
    "    # \"gfniw\",\n",
    "    \"gfnsmc\",\n",
    "    # \"gfnbuf\",\n",
    "    # \"gfnrbuf\",\n",
    "    # \"gfnlbuf\",\n",
    "    # \"gfnuiwbuf\",\n",
    "    \"gfnpiwbuf\",\n",
    "    \"gfnsmcbuf\",\n",
    "    \"gfnsmcpiwbuf\",\n",
    "]\n",
    "\n",
    "wandb_tag_filter = {\n",
    "    \"$all\": [\"final\", \"main_w_lp\"],\n",
    "    \"$nin\": [\"hidden\", \"legacy\"],\n",
    "}\n",
    "\n",
    "wandb_filter = {\n",
    "    \"tags\": wandb_tag_filter,\n",
    "    \"config.algorithm_model_use_lp\": True,\n",
    "}\n",
    "\n",
    "runs = defaultdict(dict)\n",
    "\n",
    "# first key is target_name-dim\n",
    "for target_name, dim in zip(target_names, dims):\n",
    "    wandb_filter[\"config.target_name\"] = target_name\n",
    "    wandb_filter[\"config.target_dim\"] = dim\n",
    "\n",
    "    for algorithm_name in algorithm_names:\n",
    "        wandb_filter[\"config.wandb_name\"] = algorithm_name\n",
    "        runs[f\"{target_name}-{dim}d\"][algorithm_name] = api.runs(f\"sanghyeok-choi/sampling_bench\", filters=wandb_filter)\n",
    "        print(f\"Number of runs in {target_name}-{dim}d/{algorithm_name}: {len(runs[f'{target_name}-{dim}d'][algorithm_name])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare dataframes\n",
    "\n",
    "# Prepare metrics (columns)\n",
    "metrics = [\"KL/eubo\", \"KL/elbo\", \"logZ/reverse\", \"discrepancies/sd\", \"discrepancies/mmd\"]\n",
    "metrics_std = [f\"{m}_std\" for m in metrics]\n",
    "\n",
    "# make a dataframe with group_keys as multi-index and metrics as columns\n",
    "metrics_dfs = {}\n",
    "for target_name_dim in runs.keys():\n",
    "    # row is algorithm_name\n",
    "    # column is metrics_columns\n",
    "    metrics_dfs[target_name_dim] = pd.DataFrame(columns=metrics + metrics_std) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading runs for many_well-64d\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([38400, 38800, 39200, 39600, 39999], dtype='int64', name='_step')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     28\u001b[39m futures = {\n\u001b[32m     29\u001b[39m     executor.submit(\n\u001b[32m     30\u001b[39m         process_group_key, \n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m     ): key \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys\n\u001b[32m     37\u001b[39m }\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m as_completed(futures):\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     result = \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     key = result[\u001b[33m'\u001b[39m\u001b[33mkey\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m# Store results in dataframes\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gfn-is/lib/python3.11/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gfn-is/lib/python3.11/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gfn-is/lib/python3.11/concurrent/futures/thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mprocess_group_key\u001b[39m\u001b[34m(alg_name, alg_runs, metrics, timesteps, n_seeds)\u001b[39m\n\u001b[32m      7\u001b[39m     last_5_df = run.history(samples=timesteps[-\u001b[32m1\u001b[39m] + \u001b[32m1\u001b[39m, keys=metrics)\n\u001b[32m      8\u001b[39m     last_5_df.set_index(\u001b[33m\"\u001b[39m\u001b[33m_step\u001b[39m\u001b[33m\"\u001b[39m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     last_5_values = \u001b[43mlast_5_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m]\u001b[49m.values\n\u001b[32m     10\u001b[39m     metrics_arr[i] = last_5_values.mean(axis=\u001b[32m0\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mkey\u001b[39m\u001b[33m'\u001b[39m: alg_name,\n\u001b[32m     14\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m: metrics_arr.mean(axis=\u001b[32m0\u001b[39m),  \u001b[38;5;66;03m# average over 5 seeds\u001b[39;00m\n\u001b[32m     15\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mstd\u001b[39m\u001b[33m'\u001b[39m: metrics_arr.std(axis=\u001b[32m0\u001b[39m),  \u001b[38;5;66;03m# std over 5 seeds\u001b[39;00m\n\u001b[32m     16\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gfn-is/lib/python3.11/site-packages/pandas/core/indexing.py:1184\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1182\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_scalar_access(key):\n\u001b[32m   1183\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._get_value(*key, takeable=\u001b[38;5;28mself\u001b[39m._takeable)\n\u001b[32m-> \u001b[39m\u001b[32m1184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1186\u001b[39m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[32m   1187\u001b[39m     axis = \u001b[38;5;28mself\u001b[39m.axis \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gfn-is/lib/python3.11/site-packages/pandas/core/indexing.py:1375\u001b[39m, in \u001b[36m_LocIndexer._getitem_tuple\u001b[39m\u001b[34m(self, tup)\u001b[39m\n\u001b[32m   1373\u001b[39m \u001b[38;5;66;03m# ugly hack for GH #836\u001b[39;00m\n\u001b[32m   1374\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._multi_take_opportunity(tup):\n\u001b[32m-> \u001b[39m\u001b[32m1375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_multi_take\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_tuple_same_dim(tup)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gfn-is/lib/python3.11/site-packages/pandas/core/indexing.py:1326\u001b[39m, in \u001b[36m_LocIndexer._multi_take\u001b[39m\u001b[34m(self, tup)\u001b[39m\n\u001b[32m   1310\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1311\u001b[39m \u001b[33;03mCreate the indexers for the passed tuple of keys, and\u001b[39;00m\n\u001b[32m   1312\u001b[39m \u001b[33;03mexecutes the take operation. This allows the take operation to be\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1323\u001b[39m \u001b[33;03mvalues: same type as the object being indexed\u001b[39;00m\n\u001b[32m   1324\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1325\u001b[39m \u001b[38;5;66;03m# GH 836\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1326\u001b[39m d = \u001b[43m{\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_AXIS_ORDERS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._reindex_with_indexers(d, copy=\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gfn-is/lib/python3.11/site-packages/pandas/core/indexing.py:1327\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1310\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1311\u001b[39m \u001b[33;03mCreate the indexers for the passed tuple of keys, and\u001b[39;00m\n\u001b[32m   1312\u001b[39m \u001b[33;03mexecutes the take operation. This allows the take operation to be\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1323\u001b[39m \u001b[33;03mvalues: same type as the object being indexed\u001b[39;00m\n\u001b[32m   1324\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1325\u001b[39m \u001b[38;5;66;03m# GH 836\u001b[39;00m\n\u001b[32m   1326\u001b[39m d = {\n\u001b[32m-> \u001b[39m\u001b[32m1327\u001b[39m     axis: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1328\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m (key, axis) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tup, \u001b[38;5;28mself\u001b[39m.obj._AXIS_ORDERS)\n\u001b[32m   1329\u001b[39m }\n\u001b[32m   1330\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._reindex_with_indexers(d, copy=\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gfn-is/lib/python3.11/site-packages/pandas/core/indexing.py:1558\u001b[39m, in \u001b[36m_LocIndexer._get_listlike_indexer\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1555\u001b[39m ax = \u001b[38;5;28mself\u001b[39m.obj._get_axis(axis)\n\u001b[32m   1556\u001b[39m axis_name = \u001b[38;5;28mself\u001b[39m.obj._get_axis_name(axis)\n\u001b[32m-> \u001b[39m\u001b[32m1558\u001b[39m keyarr, indexer = \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1560\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gfn-is/lib/python3.11/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/gfn-is/lib/python3.11/site-packages/pandas/core/indexes/base.py:6261\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6261\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index([38400, 38800, 39200, 39600, 39999], dtype='int64', name='_step')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "\n",
    "def process_group_key(alg_name, alg_runs, metrics, timesteps, n_seeds):\n",
    "    # Save to numpy array first\n",
    "    metrics_arr = np.zeros((n_seeds, len(metrics)))\n",
    "\n",
    "    for i, run in enumerate(alg_runs):\n",
    "        # Fetch last 5 metrics\n",
    "        last_5_df = run.history(samples=timesteps[-1] + 1, keys=metrics)\n",
    "        last_5_df.set_index(\"_step\", inplace=True)\n",
    "        last_5_values = last_5_df.loc[timesteps, metrics].values\n",
    "        metrics_arr[i] = last_5_values.mean(axis=0)\n",
    "\n",
    "    return {\n",
    "        'key': alg_name,\n",
    "        'mean': metrics_arr.mean(axis=0),  # average over 5 seeds\n",
    "        'std': metrics_arr.std(axis=0),  # std over 5 seeds\n",
    "    }\n",
    "\n",
    "\n",
    "last_5_timesteps = [38400, 38800, 39200, 39600, 39999]  # to be averaged\n",
    "n_seeds = 5\n",
    "\n",
    "for target_name_dim in runs.keys():\n",
    "    print(f\"Downloading runs for {target_name_dim}\")\n",
    "\n",
    "    target_runs = runs[target_name_dim]\n",
    "    keys = target_runs.keys()\n",
    "    with ThreadPoolExecutor(max_workers=min(32, len(runs[target_name_dim]))) as executor:\n",
    "        futures = {\n",
    "            executor.submit(\n",
    "                process_group_key, \n",
    "                key,\n",
    "                target_runs[key],\n",
    "                metrics,\n",
    "                last_5_timesteps,\n",
    "                n_seeds,\n",
    "            ): key for key in keys\n",
    "        }\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            key = result['key']\n",
    "\n",
    "            # Store results in dataframes\n",
    "            metrics_dfs[target_name_dim].loc[key, metrics] = result['mean']\n",
    "            metrics_dfs[target_name_dim].loc[key, metrics_std] = result['std']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm            & Robot4 (10d) MMD         & Robot4 (10d) Sinkhorn    & MoS (50d) MMD            & MoS (50d) Sinkhorn       & GMM40 (50d) MMD          & GMM40 (50d) Sinkhorn    \n",
      "PIS                 \n",
      "\t& 0.593\\scriptsize$\\pm$0.026 \n",
      "\t& 3106.73\\scriptsize$\\pm$684.05 \n",
      "\t& 0.366\\scriptsize$\\pm$0.025 \n",
      "\t& 2324.69\\scriptsize$\\pm$81.66 \n",
      "\t& 0.110\\scriptsize$\\pm$0.002 \n",
      "\t& 16425.73\\scriptsize$\\pm$261.31 \n",
      "\\\\\n",
      "DDS                 \n",
      "\t& 1.381\\scriptsize$\\pm$0.004 \n",
      "\t& 6.22e+05\\scriptsize$\\pm$8.01e+05 \n",
      "\t& 0.245\\scriptsize$\\pm$0.016 \n",
      "\t& 2170.75\\scriptsize$\\pm$24.29 \n",
      "\t& 0.050\\scriptsize$\\pm$0.001 \n",
      "\t& 6882.66\\scriptsize$\\pm$125.25 \n",
      "\\\\\n",
      "LV                  \n",
      "\t& 0.422\\scriptsize$\\pm$0.002 \n",
      "\t& 1.71\\scriptsize$\\pm$0.01 \n",
      "\t& 0.350\\scriptsize$\\pm$0.007 \n",
      "\t& 2175.86\\scriptsize$\\pm$16.75 \n",
      "\t& 0.036\\scriptsize$\\pm$0.000 \n",
      "\t& 3952.22\\scriptsize$\\pm$97.14 \n",
      "\\\\\n",
      "TB                  \n",
      "\t& 0.424\\scriptsize$\\pm$0.001 \n",
      "\t& 1.72\\scriptsize$\\pm$0.01 \n",
      "\t& 0.315\\scriptsize$\\pm$0.023 \n",
      "\t& 2128.50\\scriptsize$\\pm$64.94 \n",
      "\t& 0.036\\scriptsize$\\pm$0.001 \n",
      "\t& 3903.95\\scriptsize$\\pm$139.18 \n",
      "\\\\\n",
      "\\hspace\\{2pt\\}+ SMC \n",
      "\t& 0.778\\scriptsize$\\pm$0.339 \n",
      "\t& 64.48\\scriptsize$\\pm$103.61 \n",
      "\t& 0.428\\scriptsize$\\pm$0.044 \n",
      "\t& 2416.52\\scriptsize$\\pm$104.43 \n",
      "\t& 0.194\\scriptsize$\\pm$0.315 \n",
      "\t& 7.48e+06\\scriptsize$\\pm$1.50e+07 \n",
      "\\\\\n",
      "\\hspace\\{2pt\\}+ IW-Buf\n",
      "\t& 0.318\\scriptsize$\\pm$0.003 \n",
      "\t& 1.27\\scriptsize$\\pm$0.01 \n",
      "\t& 0.442\\scriptsize$\\pm$0.022 \n",
      "\t& 2505.42\\scriptsize$\\pm$58.47 \n",
      "\t& 0.038\\scriptsize$\\pm$0.001 \n",
      "\t& 4284.49\\scriptsize$\\pm$170.43 \n",
      "\\\\\n",
      "\\hspace\\{2pt\\}+ SMC + IW-Buf\n",
      "\t& 0.103\\scriptsize$\\pm$0.110 \n",
      "\t& 0.39\\scriptsize$\\pm$0.44 \n",
      "\t& 0.299\\scriptsize$\\pm$0.043 \n",
      "\t& 2017.86\\scriptsize$\\pm$131.56 \n",
      "\t& 0.035\\scriptsize$\\pm$0.001 \n",
      "\t& 3579.17\\scriptsize$\\pm$163.43 \n",
      "\\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def print_latex_table(\n",
    "    target_names: list[str],\n",
    "    target_names_to_display_name: dict[str, str],\n",
    "    metrics: list[str],\n",
    "    metric_names: list[str],\n",
    "    final_metrics_dfs: dict[str, pd.DataFrame],\n",
    "):\n",
    "    # header = f\"{'Algorithm': <150}\"\n",
    "    # for target_name in target_names:\n",
    "    #     name, dim = target_name.replace('_', '').split('-')\n",
    "    #     for metric_name in metric_names:\n",
    "    #         col = f\"{name.upper()}({dim}) {metric_name}\"\n",
    "    #         header += f\" & {col: <24}\"\n",
    "    # header += \"\\\\\\\\\"\n",
    "    # print(header)\n",
    "\n",
    "    # Print latex table with column: target_names[0]-elbo & target_names[0]-eubo & target_names[1]-elbo & energy_names[1]-eubo & ...\n",
    "    indices = final_metrics_dfs[target_names[0]].index\n",
    "    for df in final_metrics_dfs.values():\n",
    "        if not np.all(df.index == indices):\n",
    "            raise ValueError(\"All dataframes must have the same index\")\n",
    "\n",
    "    out = f\"{'Algorithm': <20}\"\n",
    "    for target_name in target_names:\n",
    "        name, dim = target_name.split('-')\n",
    "        for metric_name in metric_names:\n",
    "            col = f\"{target_names_to_display_name[target_name]} {metric_name}\"\n",
    "            out += f\" & {col: <24}\"\n",
    "    out += \"\\n\"\n",
    "\n",
    "    for idx in indices:\n",
    "        out += f\"{idx: <20}\\n\"\n",
    "        for target_name in target_names:\n",
    "            temp_df = final_metrics_dfs[target_name].loc[idx]\n",
    "            temp_df = final_metrics_dfs[target_name].loc[idx]\n",
    "            for metric in metrics:\n",
    "                val, std = temp_df[metric], temp_df[f\"{metric}_std\"]\n",
    "                if val < -1e5 or val > 1e5:\n",
    "                    # Convert to scientific notation\n",
    "                    record = f\"{val:.2e}\\scriptsize$\\pm${std:0.2e} \\n\"\n",
    "                else:\n",
    "                    if metric == \"discrepancies/mmd\":\n",
    "                        record = f\"{val:0.3f}\\scriptsize$\\pm${std:0.3f} \\n\"\n",
    "                    else:\n",
    "                        record = f\"{val:0.2f}\\scriptsize$\\pm${std:0.2f} \\n\"\n",
    "                out += f\"\\t& {record: <24}\"\n",
    "        out += \"\\\\\\\\\"\n",
    "        out += \"\\n\"\n",
    "    print(out)\n",
    "    \n",
    "\n",
    "analysis_name = \"main\"\n",
    "lp = [False]\n",
    "\n",
    "metrics = [\"discrepancies/mmd\", \"discrepancies/sd\"]\n",
    "metric_names = [\"MMD\", \"Sinkhorn\"]\n",
    "\n",
    "run_name_to_display_name = OrderedDict({\n",
    "    \"pis\": \"PIS\",\n",
    "    \"dds\": \"DDS\",\n",
    "    \"lv\": \"LV\",\n",
    "    \"tb\": \"TB\",\n",
    "    \"gfnsmc\": \"\\hspace\\{2pt\\}+ SMC\",\n",
    "    # \"gfnbuf\": \"\\hspace\\{2pt\\}+ SMC\",\n",
    "    # \"gfnrbuf\": \"\\hspace\\{2pt\\}+ R-Buf\",\n",
    "    # \"gfnlbuf\": \"\\hspace\\{2pt\\}+ L-Buf\",\n",
    "    # \"gfnuiwbuf\": \"\\hspace\\{2pt\\}+ UIW-Buf\",\n",
    "    \"gfnpiwbuf\": \"\\hspace\\{2pt\\}+ IW-Buf\",\n",
    "    # \"gfnsmcbuf\": \"\\hspace\\{2pt\\}+ SMC + Buf\",\n",
    "    \"gfnsmcpiwbuf\": \"\\hspace\\{2pt\\}+ SMC + IW-Buf\",\n",
    "})\n",
    "\n",
    "target_names_to_display_name = {\n",
    "    \"funnel-10d\": \"Funnel (10d)\",\n",
    "    \"planar_robot_4goal-10d\": \"Robot4 (10d)\",\n",
    "    \"student_t_mixture-50d\": \"MoS (50d)\",\n",
    "    \"gaussian_mixture40-50d\": \"GMM40 (50d)\",\n",
    "    \"many_well-64d\": \"ManyWell (64d)\",\n",
    "}\n",
    "\n",
    "new_dfs = {key: df.copy() for key, df in metrics_dfs.items()}\n",
    "for key, df in new_dfs.items():\n",
    "    df.index = df.index.map(run_name_to_display_name)\n",
    "    # Filter out keys that are not in run_name_to_display_name\n",
    "    df = df[df.index.isin(list(run_name_to_display_name.values()))]\n",
    "    df = df.reindex(list(run_name_to_display_name.values()))\n",
    "    new_dfs[key] = df\n",
    "\n",
    "# save_final_metrics_dfs_to_csv(energy_names, metrics, metric_names, new_df, analysis_name)\n",
    "print_latex_table(\n",
    "    list(runs.keys()),\n",
    "    target_names_to_display_name,\n",
    "    metrics,\n",
    "    metric_names,\n",
    "    new_dfs,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfn-is",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
